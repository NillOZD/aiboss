{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP6BRQ0vAtIEw6jNW2sack3"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9mBi4-NGGFp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/bilkav.com_Churn_Modelling.csv\")"
      ],
      "metadata": {
        "id": "6txYsJPPHscG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.iloc[:, 3:13]\n",
        "Y = data.iloc[:, 13]"
      ],
      "metadata": {
        "id": "D8SWJ7VdHs9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = pd.get_dummies(X)\n",
        "X.drop(\"Gender_Female\", axis=1, inplace=True)\n",
        "X.rename(columns = {\"Gender_Male\": \"Gender\"}, inplace=True) # male = 1 , female = 0"
      ],
      "metadata": {
        "id": "jMUw9TY_Hs_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(X,Y, test_size= 0.20, random_state= 42)"
      ],
      "metadata": {
        "id": "FCPgJE5KHtCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "HEE7Qk_jsRKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = y_train.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "wdEwBSczsuCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras"
      ],
      "metadata": {
        "id": "xkM9dQ4kIMN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "mm = MinMaxScaler()\n",
        "X = mm.fit_transform(X)"
      ],
      "metadata": {
        "id": "mQA4bKXWHtEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(X,Y, test_size= 0.20, random_state= 42)"
      ],
      "metadata": {
        "id": "DdIS_Q4BE0aj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sequential"
      ],
      "metadata": {
        "id": "nK6xsoJKxK_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = keras.metrics.BinaryAccuracy()\n",
        "\n",
        "# Prepare our layer, loss, and optimizer.\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.layers.Dense(32, activation=\"relu\"),\n",
        "        keras.layers.Dense(12, activation=\"relu\"),\n",
        "        keras.layers.Dense(1),\n",
        "    ]\n",
        ")\n",
        "\n",
        "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.fit(x_train, y_train, epochs= 100)\n",
        "\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred = (y_pred > 0.5)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_pred, y_test)\n",
        "\n",
        "print(conf_matrix)\n",
        "print(classification_report(y_pred, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYUz0wPBHtHD",
        "outputId": "1448963d-e91b-4b5d-cdd5-3072646d9360"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "250/250 [==============================] - 2s 2ms/step - loss: 0.9179 - accuracy: 0.7713\n",
            "Epoch 2/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4923 - accuracy: 0.7905\n",
            "Epoch 3/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4791 - accuracy: 0.7930\n",
            "Epoch 4/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.7975\n",
            "Epoch 5/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.4575 - accuracy: 0.8010\n",
            "Epoch 6/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.4361 - accuracy: 0.8098\n",
            "Epoch 7/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.4265 - accuracy: 0.8140\n",
            "Epoch 8/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.4188 - accuracy: 0.8221\n",
            "Epoch 9/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.4100 - accuracy: 0.8244\n",
            "Epoch 10/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.4048 - accuracy: 0.8278\n",
            "Epoch 11/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.4026 - accuracy: 0.8326\n",
            "Epoch 12/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.8342\n",
            "Epoch 13/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.4143 - accuracy: 0.8196\n",
            "Epoch 14/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3926 - accuracy: 0.8347\n",
            "Epoch 15/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.4169 - accuracy: 0.8317\n",
            "Epoch 16/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.4068 - accuracy: 0.8379\n",
            "Epoch 17/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3992 - accuracy: 0.8441\n",
            "Epoch 18/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3907 - accuracy: 0.8446\n",
            "Epoch 19/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3907 - accuracy: 0.8429\n",
            "Epoch 20/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3880 - accuracy: 0.8466\n",
            "Epoch 21/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3844 - accuracy: 0.8422\n",
            "Epoch 22/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.4303 - accuracy: 0.8231\n",
            "Epoch 23/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3907 - accuracy: 0.8397\n",
            "Epoch 24/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3825 - accuracy: 0.8464\n",
            "Epoch 25/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4031 - accuracy: 0.8340\n",
            "Epoch 26/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3962 - accuracy: 0.8411\n",
            "Epoch 27/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3838 - accuracy: 0.8464\n",
            "Epoch 28/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3816 - accuracy: 0.8469\n",
            "Epoch 29/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3824 - accuracy: 0.8490\n",
            "Epoch 30/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3746 - accuracy: 0.8504\n",
            "Epoch 31/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3669 - accuracy: 0.8468\n",
            "Epoch 32/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3712 - accuracy: 0.8440\n",
            "Epoch 33/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3658 - accuracy: 0.8494\n",
            "Epoch 34/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3607 - accuracy: 0.8511\n",
            "Epoch 35/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3615 - accuracy: 0.8515\n",
            "Epoch 36/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3617 - accuracy: 0.8504\n",
            "Epoch 37/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3633 - accuracy: 0.8522\n",
            "Epoch 38/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3641 - accuracy: 0.8510\n",
            "Epoch 39/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3625 - accuracy: 0.8516\n",
            "Epoch 40/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3603 - accuracy: 0.8534\n",
            "Epoch 41/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3617 - accuracy: 0.8521\n",
            "Epoch 42/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3590 - accuracy: 0.8537\n",
            "Epoch 43/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3562 - accuracy: 0.8501\n",
            "Epoch 44/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3517 - accuracy: 0.8558\n",
            "Epoch 45/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3541 - accuracy: 0.8528\n",
            "Epoch 46/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3598 - accuracy: 0.8537\n",
            "Epoch 47/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3631 - accuracy: 0.8536\n",
            "Epoch 48/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.8316\n",
            "Epoch 49/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3864 - accuracy: 0.8447\n",
            "Epoch 50/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3757 - accuracy: 0.8530\n",
            "Epoch 51/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3717 - accuracy: 0.8545\n",
            "Epoch 52/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3686 - accuracy: 0.8541\n",
            "Epoch 53/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3730 - accuracy: 0.8526\n",
            "Epoch 54/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3885 - accuracy: 0.8482\n",
            "Epoch 55/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3628 - accuracy: 0.8515\n",
            "Epoch 56/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3593 - accuracy: 0.8537\n",
            "Epoch 57/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3564 - accuracy: 0.8546\n",
            "Epoch 58/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3565 - accuracy: 0.8531\n",
            "Epoch 59/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3524 - accuracy: 0.8559\n",
            "Epoch 60/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3595 - accuracy: 0.8543\n",
            "Epoch 61/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3581 - accuracy: 0.8570\n",
            "Epoch 62/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3544 - accuracy: 0.8536\n",
            "Epoch 63/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3532 - accuracy: 0.8556\n",
            "Epoch 64/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3508 - accuracy: 0.8583\n",
            "Epoch 65/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3501 - accuracy: 0.8568\n",
            "Epoch 66/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3605 - accuracy: 0.8541\n",
            "Epoch 67/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3575 - accuracy: 0.8574\n",
            "Epoch 68/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3508 - accuracy: 0.8558\n",
            "Epoch 69/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3470 - accuracy: 0.8569\n",
            "Epoch 70/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3444 - accuracy: 0.8575\n",
            "Epoch 71/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3452 - accuracy: 0.8597\n",
            "Epoch 72/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3458 - accuracy: 0.8584\n",
            "Epoch 73/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3489 - accuracy: 0.8569\n",
            "Epoch 74/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.4305 - accuracy: 0.8370\n",
            "Epoch 75/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3551 - accuracy: 0.8490\n",
            "Epoch 76/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3494 - accuracy: 0.8541\n",
            "Epoch 77/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3477 - accuracy: 0.8564\n",
            "Epoch 78/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3446 - accuracy: 0.8587\n",
            "Epoch 79/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3441 - accuracy: 0.8561\n",
            "Epoch 80/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3453 - accuracy: 0.8586\n",
            "Epoch 81/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3411 - accuracy: 0.8580\n",
            "Epoch 82/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3407 - accuracy: 0.8609\n",
            "Epoch 83/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3443 - accuracy: 0.8596\n",
            "Epoch 84/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3420 - accuracy: 0.8589\n",
            "Epoch 85/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3410 - accuracy: 0.8601\n",
            "Epoch 86/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3394 - accuracy: 0.8599\n",
            "Epoch 87/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3415 - accuracy: 0.8610\n",
            "Epoch 88/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3367 - accuracy: 0.8595\n",
            "Epoch 89/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3388 - accuracy: 0.8633\n",
            "Epoch 90/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3362 - accuracy: 0.8614\n",
            "Epoch 91/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3357 - accuracy: 0.8602\n",
            "Epoch 92/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3360 - accuracy: 0.8609\n",
            "Epoch 93/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3372 - accuracy: 0.8602\n",
            "Epoch 94/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3322 - accuracy: 0.8634\n",
            "Epoch 95/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8631\n",
            "Epoch 96/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.8589\n",
            "Epoch 97/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3320 - accuracy: 0.8606\n",
            "Epoch 98/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3314 - accuracy: 0.8627\n",
            "Epoch 99/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3319 - accuracy: 0.8633\n",
            "Epoch 100/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8627\n",
            "63/63 [==============================] - 0s 928us/step\n",
            "[[1556  236]\n",
            " [  51  157]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.97      0.87      0.92      1792\n",
            "        True       0.40      0.75      0.52       208\n",
            "\n",
            "    accuracy                           0.86      2000\n",
            "   macro avg       0.68      0.81      0.72      2000\n",
            "weighted avg       0.91      0.86      0.87      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#now let's use stoa techniques"
      ],
      "metadata": {
        "id": "w2-2yAGKxyZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.layers.Dense(32, activation=\"relu\"),\n",
        "        keras.layers.Dropout(0.05),\n",
        "        keras.layers.LayerNormalization(),\n",
        "        keras.layers.Dense(12, activation=\"relu\"),\n",
        "        keras.layers.Dropout(0.05),\n",
        "        keras.layers.LayerNormalization(),\n",
        "        keras.layers.Dense(1),\n",
        "    ]\n",
        ")\n",
        "\n",
        "loss_fn = keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_fn, metrics=[\"accuracy\"])\n",
        "model.fit(x_train, y_train, epochs= 100)\n",
        "\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred = (y_pred > 0.5)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_pred, y_test)\n",
        "\n",
        "print(conf_matrix)\n",
        "print(classification_report(y_pred, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FamGw6Rvxybx",
        "outputId": "0aa01b2f-71eb-4a99-b3c8-822639e4ec3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "250/250 [==============================] - 3s 2ms/step - loss: 0.5640 - accuracy: 0.7853\n",
            "Epoch 2/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5192 - accuracy: 0.7944\n",
            "Epoch 3/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5024 - accuracy: 0.7945\n",
            "Epoch 4/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4938 - accuracy: 0.7947\n",
            "Epoch 5/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4864 - accuracy: 0.7952\n",
            "Epoch 6/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4788 - accuracy: 0.7970\n",
            "Epoch 7/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4662 - accuracy: 0.7981\n",
            "Epoch 8/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4650 - accuracy: 0.7991\n",
            "Epoch 9/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4594 - accuracy: 0.8018\n",
            "Epoch 10/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4533 - accuracy: 0.8048\n",
            "Epoch 11/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4457 - accuracy: 0.8055\n",
            "Epoch 12/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4346 - accuracy: 0.8100\n",
            "Epoch 13/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4368 - accuracy: 0.8083\n",
            "Epoch 14/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4293 - accuracy: 0.8138\n",
            "Epoch 15/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4295 - accuracy: 0.8124\n",
            "Epoch 16/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4283 - accuracy: 0.8156\n",
            "Epoch 17/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4216 - accuracy: 0.8201\n",
            "Epoch 18/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4193 - accuracy: 0.8192\n",
            "Epoch 19/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4181 - accuracy: 0.8185\n",
            "Epoch 20/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4181 - accuracy: 0.8191\n",
            "Epoch 21/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4114 - accuracy: 0.8181\n",
            "Epoch 22/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4102 - accuracy: 0.8241\n",
            "Epoch 23/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4121 - accuracy: 0.8235\n",
            "Epoch 24/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4145 - accuracy: 0.8246\n",
            "Epoch 25/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4093 - accuracy: 0.8260\n",
            "Epoch 26/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4134 - accuracy: 0.8225\n",
            "Epoch 27/100\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.4078 - accuracy: 0.8236\n",
            "Epoch 28/100\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.4042 - accuracy: 0.8259\n",
            "Epoch 29/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4060 - accuracy: 0.8251\n",
            "Epoch 30/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4062 - accuracy: 0.8256\n",
            "Epoch 31/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4044 - accuracy: 0.8267\n",
            "Epoch 32/100\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.4060 - accuracy: 0.8270\n",
            "Epoch 33/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3981 - accuracy: 0.8279\n",
            "Epoch 34/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3951 - accuracy: 0.8305\n",
            "Epoch 35/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4003 - accuracy: 0.8284\n",
            "Epoch 36/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4059 - accuracy: 0.8238\n",
            "Epoch 37/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3955 - accuracy: 0.8329\n",
            "Epoch 38/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4012 - accuracy: 0.8276\n",
            "Epoch 39/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3966 - accuracy: 0.8329\n",
            "Epoch 40/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3902 - accuracy: 0.8364\n",
            "Epoch 41/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3981 - accuracy: 0.8309\n",
            "Epoch 42/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3908 - accuracy: 0.8316\n",
            "Epoch 43/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3944 - accuracy: 0.8310\n",
            "Epoch 44/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3965 - accuracy: 0.8322\n",
            "Epoch 45/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3954 - accuracy: 0.8334\n",
            "Epoch 46/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3943 - accuracy: 0.8331\n",
            "Epoch 47/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3959 - accuracy: 0.8290\n",
            "Epoch 48/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3890 - accuracy: 0.8350\n",
            "Epoch 49/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3961 - accuracy: 0.8319\n",
            "Epoch 50/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3891 - accuracy: 0.8322\n",
            "Epoch 51/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3952 - accuracy: 0.8329\n",
            "Epoch 52/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3983 - accuracy: 0.8316\n",
            "Epoch 53/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3920 - accuracy: 0.8309\n",
            "Epoch 54/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3848 - accuracy: 0.8357\n",
            "Epoch 55/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3983 - accuracy: 0.8299\n",
            "Epoch 56/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3918 - accuracy: 0.8344\n",
            "Epoch 57/100\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.3939 - accuracy: 0.8300\n",
            "Epoch 58/100\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.3915 - accuracy: 0.8364\n",
            "Epoch 59/100\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.3905 - accuracy: 0.8326\n",
            "Epoch 60/100\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.3858 - accuracy: 0.8356\n",
            "Epoch 61/100\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.3908 - accuracy: 0.8338\n",
            "Epoch 62/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3897 - accuracy: 0.8342\n",
            "Epoch 63/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3929 - accuracy: 0.8290\n",
            "Epoch 64/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3933 - accuracy: 0.8299\n",
            "Epoch 65/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3873 - accuracy: 0.8361\n",
            "Epoch 66/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3936 - accuracy: 0.8339\n",
            "Epoch 67/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3945 - accuracy: 0.8300\n",
            "Epoch 68/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3884 - accuracy: 0.8336\n",
            "Epoch 69/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3912 - accuracy: 0.8342\n",
            "Epoch 70/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3880 - accuracy: 0.8324\n",
            "Epoch 71/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3912 - accuracy: 0.8340\n",
            "Epoch 72/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3849 - accuracy: 0.8369\n",
            "Epoch 73/100\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.3909 - accuracy: 0.8331\n",
            "Epoch 74/100\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.3925 - accuracy: 0.8332\n",
            "Epoch 75/100\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.3885 - accuracy: 0.8359\n",
            "Epoch 76/100\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.3897 - accuracy: 0.8322\n",
            "Epoch 77/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3856 - accuracy: 0.8340\n",
            "Epoch 78/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3844 - accuracy: 0.8335\n",
            "Epoch 79/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3850 - accuracy: 0.8353\n",
            "Epoch 80/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3915 - accuracy: 0.8360\n",
            "Epoch 81/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3865 - accuracy: 0.8364\n",
            "Epoch 82/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3823 - accuracy: 0.8388\n",
            "Epoch 83/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3853 - accuracy: 0.8360\n",
            "Epoch 84/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3879 - accuracy: 0.8371\n",
            "Epoch 85/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3863 - accuracy: 0.8340\n",
            "Epoch 86/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3875 - accuracy: 0.8330\n",
            "Epoch 87/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3926 - accuracy: 0.8304\n",
            "Epoch 88/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3827 - accuracy: 0.8386\n",
            "Epoch 89/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3834 - accuracy: 0.8364\n",
            "Epoch 90/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3837 - accuracy: 0.8361\n",
            "Epoch 91/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3847 - accuracy: 0.8376\n",
            "Epoch 92/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3860 - accuracy: 0.8355\n",
            "Epoch 93/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3842 - accuracy: 0.8344\n",
            "Epoch 94/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3913 - accuracy: 0.8317\n",
            "Epoch 95/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3895 - accuracy: 0.8351\n",
            "Epoch 96/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3869 - accuracy: 0.8321\n",
            "Epoch 97/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3860 - accuracy: 0.8334\n",
            "Epoch 98/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3917 - accuracy: 0.8313\n",
            "Epoch 99/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3816 - accuracy: 0.8347\n",
            "Epoch 100/100\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.3805 - accuracy: 0.8421\n",
            "63/63 [==============================] - 0s 2ms/step\n",
            "[[1595  296]\n",
            " [  12   97]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.99      0.84      0.91      1891\n",
            "        True       0.25      0.89      0.39       109\n",
            "\n",
            "    accuracy                           0.85      2000\n",
            "   macro avg       0.62      0.87      0.65      2000\n",
            "weighted avg       0.95      0.85      0.88      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Batch Norm performed worse so I'm using LayerNorm"
      ],
      "metadata": {
        "id": "THVCZyo29Ew3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Leaky Relu performance: F1 >>> 0.92 False, 0.50 True and Accuracy 0.86"
      ],
      "metadata": {
        "id": "IWx5T3Rx9_ED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#now let's play with optimizer >>> lr 0.01"
      ],
      "metadata": {
        "id": "2MtXIU7VDU9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.layers.Dense(32, activation=\"relu\"),\n",
        "        keras.layers.Dropout(0.05),\n",
        "        keras.layers.LayerNormalization(),\n",
        "        keras.layers.Dense(12, activation=\"relu\"),\n",
        "        keras.layers.Dropout(0.05),\n",
        "        keras.layers.LayerNormalization(),\n",
        "        keras.layers.Dense(1),\n",
        "    ]\n",
        ")\n",
        "\n",
        "loss_fn = keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "optimizer = keras.optimizers.Adam(learning_rate=1e-2)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_fn, metrics=[\"accuracy\"])\n",
        "model.fit(x_train, y_train, epochs= 100)\n",
        "\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred = (y_pred > 0.5)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_pred, y_test)\n",
        "\n",
        "print(conf_matrix)\n",
        "print(classification_report(y_pred, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlKRxURdDVAF",
        "outputId": "ddf60bbb-4e59-468a-9f34-5d26aee7c5d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "250/250 [==============================] - 3s 3ms/step - loss: 0.4743 - accuracy: 0.7962\n",
            "Epoch 2/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4190 - accuracy: 0.8181\n",
            "Epoch 3/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3846 - accuracy: 0.8350\n",
            "Epoch 4/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3675 - accuracy: 0.8461\n",
            "Epoch 5/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3651 - accuracy: 0.8464\n",
            "Epoch 6/100\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.3643 - accuracy: 0.8480\n",
            "Epoch 7/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3594 - accuracy: 0.8469\n",
            "Epoch 8/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3558 - accuracy: 0.8514\n",
            "Epoch 9/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3568 - accuracy: 0.8499\n",
            "Epoch 10/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3549 - accuracy: 0.8506\n",
            "Epoch 11/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3522 - accuracy: 0.8540\n",
            "Epoch 12/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3542 - accuracy: 0.8500\n",
            "Epoch 13/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3516 - accuracy: 0.8516\n",
            "Epoch 14/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3481 - accuracy: 0.8524\n",
            "Epoch 15/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3546 - accuracy: 0.8508\n",
            "Epoch 16/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3483 - accuracy: 0.8515\n",
            "Epoch 17/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3445 - accuracy: 0.8556\n",
            "Epoch 18/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3442 - accuracy: 0.8579\n",
            "Epoch 19/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3488 - accuracy: 0.8543\n",
            "Epoch 20/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3474 - accuracy: 0.8553\n",
            "Epoch 21/100\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.3470 - accuracy: 0.8553\n",
            "Epoch 22/100\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.3465 - accuracy: 0.8514\n",
            "Epoch 23/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3469 - accuracy: 0.8534\n",
            "Epoch 24/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3454 - accuracy: 0.8534\n",
            "Epoch 25/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3431 - accuracy: 0.8544\n",
            "Epoch 26/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3447 - accuracy: 0.8547\n",
            "Epoch 27/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3434 - accuracy: 0.8549\n",
            "Epoch 28/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3436 - accuracy: 0.8549\n",
            "Epoch 29/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3462 - accuracy: 0.8539\n",
            "Epoch 30/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3494 - accuracy: 0.8547\n",
            "Epoch 31/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3432 - accuracy: 0.8564\n",
            "Epoch 32/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3447 - accuracy: 0.8531\n",
            "Epoch 33/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3408 - accuracy: 0.8537\n",
            "Epoch 34/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3429 - accuracy: 0.8540\n",
            "Epoch 35/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3413 - accuracy: 0.8554\n",
            "Epoch 36/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3445 - accuracy: 0.8558\n",
            "Epoch 37/100\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.3413 - accuracy: 0.8564\n",
            "Epoch 38/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3437 - accuracy: 0.8536\n",
            "Epoch 39/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3385 - accuracy: 0.8562\n",
            "Epoch 40/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3419 - accuracy: 0.8577\n",
            "Epoch 41/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3414 - accuracy: 0.8565\n",
            "Epoch 42/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3404 - accuracy: 0.8586\n",
            "Epoch 43/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3402 - accuracy: 0.8546\n",
            "Epoch 44/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3413 - accuracy: 0.8589\n",
            "Epoch 45/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3414 - accuracy: 0.8572\n",
            "Epoch 46/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3397 - accuracy: 0.8576\n",
            "Epoch 47/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3414 - accuracy: 0.8564\n",
            "Epoch 48/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3392 - accuracy: 0.8556\n",
            "Epoch 49/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3396 - accuracy: 0.8558\n",
            "Epoch 50/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3367 - accuracy: 0.8604\n",
            "Epoch 51/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3389 - accuracy: 0.8583\n",
            "Epoch 52/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3393 - accuracy: 0.8564\n",
            "Epoch 53/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3358 - accuracy: 0.8577\n",
            "Epoch 54/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3358 - accuracy: 0.8583\n",
            "Epoch 55/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3418 - accuracy: 0.8547\n",
            "Epoch 56/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3402 - accuracy: 0.8594\n",
            "Epoch 57/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3389 - accuracy: 0.8559\n",
            "Epoch 58/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3367 - accuracy: 0.8585\n",
            "Epoch 59/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3356 - accuracy: 0.8590\n",
            "Epoch 60/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3380 - accuracy: 0.8560\n",
            "Epoch 61/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3416 - accuracy: 0.8560\n",
            "Epoch 62/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3371 - accuracy: 0.8585\n",
            "Epoch 63/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3389 - accuracy: 0.8562\n",
            "Epoch 64/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3342 - accuracy: 0.8612\n",
            "Epoch 65/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3397 - accuracy: 0.8572\n",
            "Epoch 66/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3355 - accuracy: 0.8564\n",
            "Epoch 67/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3320 - accuracy: 0.8586\n",
            "Epoch 68/100\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.3344 - accuracy: 0.8599\n",
            "Epoch 69/100\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.3336 - accuracy: 0.8599\n",
            "Epoch 70/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3322 - accuracy: 0.8576\n",
            "Epoch 71/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3362 - accuracy: 0.8561\n",
            "Epoch 72/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3316 - accuracy: 0.8625\n",
            "Epoch 73/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3377 - accuracy: 0.8596\n",
            "Epoch 74/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3322 - accuracy: 0.8593\n",
            "Epoch 75/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3329 - accuracy: 0.8604\n",
            "Epoch 76/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3332 - accuracy: 0.8589\n",
            "Epoch 77/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3359 - accuracy: 0.8584\n",
            "Epoch 78/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3315 - accuracy: 0.8600\n",
            "Epoch 79/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3342 - accuracy: 0.8600\n",
            "Epoch 80/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3328 - accuracy: 0.8622\n",
            "Epoch 81/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3339 - accuracy: 0.8583\n",
            "Epoch 82/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3323 - accuracy: 0.8587\n",
            "Epoch 83/100\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.3327 - accuracy: 0.8637\n",
            "Epoch 84/100\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.3342 - accuracy: 0.8584\n",
            "Epoch 85/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3324 - accuracy: 0.8574\n",
            "Epoch 86/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3318 - accuracy: 0.8599\n",
            "Epoch 87/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3315 - accuracy: 0.8601\n",
            "Epoch 88/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3315 - accuracy: 0.8568\n",
            "Epoch 89/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3296 - accuracy: 0.8609\n",
            "Epoch 90/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3314 - accuracy: 0.8593\n",
            "Epoch 91/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3311 - accuracy: 0.8608\n",
            "Epoch 92/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3334 - accuracy: 0.8601\n",
            "Epoch 93/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3312 - accuracy: 0.8606\n",
            "Epoch 94/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3335 - accuracy: 0.8580\n",
            "Epoch 95/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3285 - accuracy: 0.8595\n",
            "Epoch 96/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3339 - accuracy: 0.8577\n",
            "Epoch 97/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3324 - accuracy: 0.8560\n",
            "Epoch 98/100\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.3277 - accuracy: 0.8620\n",
            "Epoch 99/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3317 - accuracy: 0.8646\n",
            "Epoch 100/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3293 - accuracy: 0.8597\n",
            "63/63 [==============================] - 1s 7ms/step\n",
            "[[1577  247]\n",
            " [  30  146]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.98      0.86      0.92      1824\n",
            "        True       0.37      0.83      0.51       176\n",
            "\n",
            "    accuracy                           0.86      2000\n",
            "   macro avg       0.68      0.85      0.72      2000\n",
            "weighted avg       0.93      0.86      0.88      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# other optimizers.."
      ],
      "metadata": {
        "id": "WA3fcx4PDVCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.layers.Dense(32, activation=\"relu\"),\n",
        "        keras.layers.Dropout(0.05),\n",
        "        keras.layers.LayerNormalization(),\n",
        "        keras.layers.Dense(12, activation=\"relu\"),\n",
        "        keras.layers.Dropout(0.05),\n",
        "        keras.layers.LayerNormalization(),\n",
        "        keras.layers.Dense(1),\n",
        "    ]\n",
        ")\n"
      ],
      "metadata": {
        "id": "yABBU6a_DVFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "optimizer = keras.optimizers.RMSprop()\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_fn, metrics=[\"accuracy\"])\n",
        "model.fit(x_train, y_train, epochs= 50)\n",
        "\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred = (y_pred > 0.5)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_pred, y_test)\n",
        "\n",
        "print(conf_matrix)\n",
        "print(classification_report(y_pred, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GO_sKaRCDVIH",
        "outputId": "9d1ac421-ad76-4221-c13d-2d853ec93867"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "250/250 [==============================] - 4s 7ms/step - loss: 0.5098 - accuracy: 0.7849\n",
            "Epoch 2/50\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.4657 - accuracy: 0.7977\n",
            "Epoch 3/50\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.4518 - accuracy: 0.8011\n",
            "Epoch 4/50\n",
            "250/250 [==============================] - 2s 9ms/step - loss: 0.4402 - accuracy: 0.8029\n",
            "Epoch 5/50\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.4262 - accuracy: 0.8091\n",
            "Epoch 6/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4184 - accuracy: 0.8150\n",
            "Epoch 7/50\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.4074 - accuracy: 0.8184\n",
            "Epoch 8/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4022 - accuracy: 0.8230\n",
            "Epoch 9/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3888 - accuracy: 0.8288\n",
            "Epoch 10/50\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.3821 - accuracy: 0.8366\n",
            "Epoch 11/50\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.3804 - accuracy: 0.8372\n",
            "Epoch 12/50\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.3689 - accuracy: 0.8438\n",
            "Epoch 13/50\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.3653 - accuracy: 0.8436\n",
            "Epoch 14/50\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.3651 - accuracy: 0.8441\n",
            "Epoch 15/50\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.3627 - accuracy: 0.8459\n",
            "Epoch 16/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3600 - accuracy: 0.8491\n",
            "Epoch 17/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3609 - accuracy: 0.8494\n",
            "Epoch 18/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3570 - accuracy: 0.8464\n",
            "Epoch 19/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3577 - accuracy: 0.8500\n",
            "Epoch 20/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3564 - accuracy: 0.8509\n",
            "Epoch 21/50\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.3550 - accuracy: 0.8490\n",
            "Epoch 22/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3535 - accuracy: 0.8531\n",
            "Epoch 23/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3527 - accuracy: 0.8506\n",
            "Epoch 24/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3521 - accuracy: 0.8525\n",
            "Epoch 25/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3471 - accuracy: 0.8541\n",
            "Epoch 26/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3485 - accuracy: 0.8547\n",
            "Epoch 27/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3496 - accuracy: 0.8509\n",
            "Epoch 28/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3484 - accuracy: 0.8531\n",
            "Epoch 29/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3480 - accuracy: 0.8533\n",
            "Epoch 30/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3447 - accuracy: 0.8550\n",
            "Epoch 31/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3446 - accuracy: 0.8559\n",
            "Epoch 32/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3423 - accuracy: 0.8544\n",
            "Epoch 33/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3423 - accuracy: 0.8551\n",
            "Epoch 34/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3458 - accuracy: 0.8553\n",
            "Epoch 35/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3441 - accuracy: 0.8544\n",
            "Epoch 36/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3450 - accuracy: 0.8561\n",
            "Epoch 37/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3432 - accuracy: 0.8537\n",
            "Epoch 38/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3421 - accuracy: 0.8541\n",
            "Epoch 39/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3412 - accuracy: 0.8550\n",
            "Epoch 40/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3454 - accuracy: 0.8562\n",
            "Epoch 41/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3413 - accuracy: 0.8547\n",
            "Epoch 42/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3418 - accuracy: 0.8558\n",
            "Epoch 43/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3420 - accuracy: 0.8561\n",
            "Epoch 44/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3398 - accuracy: 0.8576\n",
            "Epoch 45/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3391 - accuracy: 0.8558\n",
            "Epoch 46/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3390 - accuracy: 0.8543\n",
            "Epoch 47/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3380 - accuracy: 0.8581\n",
            "Epoch 48/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3377 - accuracy: 0.8556\n",
            "Epoch 49/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3380 - accuracy: 0.8589\n",
            "Epoch 50/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3412 - accuracy: 0.8562\n",
            "63/63 [==============================] - 0s 3ms/step\n",
            "[[1575  249]\n",
            " [  32  144]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.98      0.86      0.92      1824\n",
            "        True       0.37      0.82      0.51       176\n",
            "\n",
            "    accuracy                           0.86      2000\n",
            "   macro avg       0.67      0.84      0.71      2000\n",
            "weighted avg       0.93      0.86      0.88      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "optimizer = keras.optimizers.SGD(learning_rate=1e-2)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_fn, metrics=[\"accuracy\"])\n",
        "model.fit(x_train, y_train, epochs= 50)\n",
        "\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred = (y_pred > 0.5)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_pred, y_test)\n",
        "\n",
        "print(conf_matrix)\n",
        "print(classification_report(y_pred, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFFDD7OJFEPS",
        "outputId": "4d07ecf2-f035-48a5-a9d5-896dc78b150d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "250/250 [==============================] - 3s 3ms/step - loss: 0.3238 - accuracy: 0.8620\n",
            "Epoch 2/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3212 - accuracy: 0.8659\n",
            "Epoch 3/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3216 - accuracy: 0.8637\n",
            "Epoch 4/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3273 - accuracy: 0.8616\n",
            "Epoch 5/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3250 - accuracy: 0.8618\n",
            "Epoch 6/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3189 - accuracy: 0.8633\n",
            "Epoch 7/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3246 - accuracy: 0.8635\n",
            "Epoch 8/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3246 - accuracy: 0.8629\n",
            "Epoch 9/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3208 - accuracy: 0.8636\n",
            "Epoch 10/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3265 - accuracy: 0.8609\n",
            "Epoch 11/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3225 - accuracy: 0.8633\n",
            "Epoch 12/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3228 - accuracy: 0.8645\n",
            "Epoch 13/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3229 - accuracy: 0.8634\n",
            "Epoch 14/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3208 - accuracy: 0.8636\n",
            "Epoch 15/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3238 - accuracy: 0.8635\n",
            "Epoch 16/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3196 - accuracy: 0.8633\n",
            "Epoch 17/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3236 - accuracy: 0.8631\n",
            "Epoch 18/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3238 - accuracy: 0.8631\n",
            "Epoch 19/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3220 - accuracy: 0.8645\n",
            "Epoch 20/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3189 - accuracy: 0.8644\n",
            "Epoch 21/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3218 - accuracy: 0.8644\n",
            "Epoch 22/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3207 - accuracy: 0.8661\n",
            "Epoch 23/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3207 - accuracy: 0.8633\n",
            "Epoch 24/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3204 - accuracy: 0.8655\n",
            "Epoch 25/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3204 - accuracy: 0.8649\n",
            "Epoch 26/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3195 - accuracy: 0.8651\n",
            "Epoch 27/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3245 - accuracy: 0.8633\n",
            "Epoch 28/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3227 - accuracy: 0.8646\n",
            "Epoch 29/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3250 - accuracy: 0.8640\n",
            "Epoch 30/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3196 - accuracy: 0.8648\n",
            "Epoch 31/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3201 - accuracy: 0.8660\n",
            "Epoch 32/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3212 - accuracy: 0.8634\n",
            "Epoch 33/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3212 - accuracy: 0.8625\n",
            "Epoch 34/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3183 - accuracy: 0.8670\n",
            "Epoch 35/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3160 - accuracy: 0.8676\n",
            "Epoch 36/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3185 - accuracy: 0.8666\n",
            "Epoch 37/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3218 - accuracy: 0.8636\n",
            "Epoch 38/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3233 - accuracy: 0.8645\n",
            "Epoch 39/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3233 - accuracy: 0.8618\n",
            "Epoch 40/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3215 - accuracy: 0.8648\n",
            "Epoch 41/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3207 - accuracy: 0.8629\n",
            "Epoch 42/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3199 - accuracy: 0.8643\n",
            "Epoch 43/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3194 - accuracy: 0.8662\n",
            "Epoch 44/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3240 - accuracy: 0.8665\n",
            "Epoch 45/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3197 - accuracy: 0.8668\n",
            "Epoch 46/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3214 - accuracy: 0.8636\n",
            "Epoch 47/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3214 - accuracy: 0.8630\n",
            "Epoch 48/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3236 - accuracy: 0.8602\n",
            "Epoch 49/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3180 - accuracy: 0.8658\n",
            "Epoch 50/50\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3189 - accuracy: 0.8671\n",
            "63/63 [==============================] - 0s 2ms/step\n",
            "[[1573  246]\n",
            " [  34  147]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.98      0.86      0.92      1819\n",
            "        True       0.37      0.81      0.51       181\n",
            "\n",
            "    accuracy                           0.86      2000\n",
            "   macro avg       0.68      0.84      0.72      2000\n",
            "weighted avg       0.92      0.86      0.88      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#performed worse with momentum"
      ],
      "metadata": {
        "id": "SQz9qTNyFuWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVwn5FbJFERn",
        "outputId": "20cd1858-2395-42b0-8f35-824216aec2e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_82 (Dense)            (None, 32)                416       \n",
            "                                                                 \n",
            " dropout_39 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " layer_normalization_16 (La  (None, 32)                64        \n",
            " yerNormalization)                                               \n",
            "                                                                 \n",
            " dense_83 (Dense)            (None, 12)                396       \n",
            "                                                                 \n",
            " dropout_40 (Dropout)        (None, 12)                0         \n",
            "                                                                 \n",
            " layer_normalization_17 (La  (None, 12)                24        \n",
            " yerNormalization)                                               \n",
            "                                                                 \n",
            " dense_84 (Dense)            (None, 1)                 13        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 913 (3.57 KB)\n",
            "Trainable params: 913 (3.57 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "r4PSEY2mIDC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BwUNeK9YIDFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#weight initialization\n",
        "#lr schedule\n",
        "#gradient clipping"
      ],
      "metadata": {
        "id": "orQeEAzZx2BS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G6MkQBLVxyeJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#using Functional API"
      ],
      "metadata": {
        "id": "XA1rT3nlENJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "mm = MinMaxScaler()\n",
        "X = mm.fit_transform(X)"
      ],
      "metadata": {
        "id": "lhyMx1QWENTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(X,Y, test_size= 0.20, random_state= 42)"
      ],
      "metadata": {
        "id": "5W6PdpHrENV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lmZzYT8F_60",
        "outputId": "1bf18ca0-d10a-436e-ca67-a6e82ecea63a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8000, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(12,), dtype=\"float32\")\n",
        "x = keras.layers.Dense(32, activation=\"relu\")(inputs)\n",
        "x = keras.layers.Dense(12, activation=\"relu\")(x)\n",
        "outputs = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "# Specify the loss, optimizer, and metrics with `compile()`.\n",
        "model.compile(\n",
        "    loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
        "    metrics=[keras.metrics.BinaryAccuracy()],\n",
        ")\n",
        "\n",
        "model.fit(x_train, y_train, epochs=20)\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred = (y_pred > 0.5)\n",
        "#model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYvlsJCYEnY8",
        "outputId": "2c4a1b26-0c17-4edc-f119-42096d9d4c6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:5805: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "250/250 [==============================] - 3s 2ms/step - loss: 0.5261 - binary_accuracy: 0.7645\n",
            "Epoch 2/20\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4633 - binary_accuracy: 0.7958\n",
            "Epoch 3/20\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4455 - binary_accuracy: 0.8073\n",
            "Epoch 4/20\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4333 - binary_accuracy: 0.8154\n",
            "Epoch 5/20\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4261 - binary_accuracy: 0.8180\n",
            "Epoch 6/20\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4179 - binary_accuracy: 0.8234\n",
            "Epoch 7/20\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4073 - binary_accuracy: 0.8260\n",
            "Epoch 8/20\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3949 - binary_accuracy: 0.8330\n",
            "Epoch 9/20\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3812 - binary_accuracy: 0.8415\n",
            "Epoch 10/20\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3717 - binary_accuracy: 0.8434\n",
            "Epoch 11/20\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3651 - binary_accuracy: 0.8482\n",
            "Epoch 12/20\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3591 - binary_accuracy: 0.8499\n",
            "Epoch 13/20\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3552 - binary_accuracy: 0.8525\n",
            "Epoch 14/20\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3512 - binary_accuracy: 0.8530\n",
            "Epoch 15/20\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3503 - binary_accuracy: 0.8539\n",
            "Epoch 16/20\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3487 - binary_accuracy: 0.8518\n",
            "Epoch 17/20\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3477 - binary_accuracy: 0.8544\n",
            "Epoch 18/20\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3465 - binary_accuracy: 0.8544\n",
            "Epoch 19/20\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3453 - binary_accuracy: 0.8547\n",
            "Epoch 20/20\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3444 - binary_accuracy: 0.8561\n",
            "63/63 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = pd.DataFrame(np.squeeze(y_pred))"
      ],
      "metadata": {
        "id": "AuzOBJ0TEnh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf_matrix = confusion_matrix(y_pred, y_test)\n",
        "\n",
        "print(conf_matrix)\n",
        "print(classification_report(y_pred, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaf-uifJEnnJ",
        "outputId": "8f332142-22e5-4c23-a80d-de4bb93ce9e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1572  257]\n",
            " [  35  136]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.98      0.86      0.92      1829\n",
            "        True       0.35      0.80      0.48       171\n",
            "\n",
            "    accuracy                           0.85      2000\n",
            "   macro avg       0.66      0.83      0.70      2000\n",
            "weighted avg       0.92      0.85      0.88      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nzcMThRKBbd",
        "outputId": "0127c76b-4bff-4922-8a90-f22517179805"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 12) dtype=float32 (created by layer 'input_7')>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "gD_uH05sIqCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparams... (maybe use keras tuner or tensorboard)"
      ],
      "metadata": {
        "id": "EBwCXP6uIqEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eY4dPIDbIqIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N7iyuuMSIqLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0HCYDVmjKBd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trying to batch my data but turns out it's not the best way to feed tabular data to an nn"
      ],
      "metadata": {
        "id": "rxcGMtXiShHa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.iloc[:, 3:]"
      ],
      "metadata": {
        "id": "q-ALwd04NDUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.get_dummies(data)\n",
        "df.drop(\"Gender_Female\", axis=1, inplace=True)\n",
        "df.rename(columns = {\"Gender_Male\": \"Gender\"}, inplace=True) # male = 1 , female = 0"
      ],
      "metadata": {
        "id": "J-Di4pG9NDXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "eC7Oii4iNbEh",
        "outputId": "d0cb7876-0229-4cf1-cd45-e6a181e0adb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
              "0             619   42       2       0.00              1          1   \n",
              "1             608   41       1   83807.86              1          0   \n",
              "2             502   42       8  159660.80              3          1   \n",
              "3             699   39       1       0.00              2          0   \n",
              "4             850   43       2  125510.82              1          1   \n",
              "...           ...  ...     ...        ...            ...        ...   \n",
              "9995          771   39       5       0.00              2          1   \n",
              "9996          516   35      10   57369.61              1          1   \n",
              "9997          709   36       7       0.00              1          0   \n",
              "9998          772   42       3   75075.31              2          1   \n",
              "9999          792   28       4  130142.79              1          1   \n",
              "\n",
              "      IsActiveMember  EstimatedSalary  Exited  Geography_France  \\\n",
              "0                  1        101348.88       1                 1   \n",
              "1                  1        112542.58       0                 0   \n",
              "2                  0        113931.57       1                 1   \n",
              "3                  0         93826.63       0                 1   \n",
              "4                  1         79084.10       0                 0   \n",
              "...              ...              ...     ...               ...   \n",
              "9995               0         96270.64       0                 1   \n",
              "9996               1        101699.77       0                 1   \n",
              "9997               1         42085.58       1                 1   \n",
              "9998               0         92888.52       1                 0   \n",
              "9999               0         38190.78       0                 1   \n",
              "\n",
              "      Geography_Germany  Geography_Spain  Gender  \n",
              "0                     0                0       0  \n",
              "1                     0                1       0  \n",
              "2                     0                0       0  \n",
              "3                     0                0       0  \n",
              "4                     0                1       0  \n",
              "...                 ...              ...     ...  \n",
              "9995                  0                0       1  \n",
              "9996                  0                0       1  \n",
              "9997                  0                0       0  \n",
              "9998                  1                0       1  \n",
              "9999                  0                0       0  \n",
              "\n",
              "[10000 rows x 13 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dd9b9794-6820-4b24-ae7e-998436b6a138\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "      <th>Geography_France</th>\n",
              "      <th>Geography_Germany</th>\n",
              "      <th>Geography_Spain</th>\n",
              "      <th>Gender</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>619</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>608</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>502</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>699</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>850</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>771</td>\n",
              "      <td>39</td>\n",
              "      <td>5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>96270.64</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>516</td>\n",
              "      <td>35</td>\n",
              "      <td>10</td>\n",
              "      <td>57369.61</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101699.77</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>709</td>\n",
              "      <td>36</td>\n",
              "      <td>7</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>42085.58</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>772</td>\n",
              "      <td>42</td>\n",
              "      <td>3</td>\n",
              "      <td>75075.31</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>92888.52</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>792</td>\n",
              "      <td>28</td>\n",
              "      <td>4</td>\n",
              "      <td>130142.79</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>38190.78</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows  13 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dd9b9794-6820-4b24-ae7e-998436b6a138')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dd9b9794-6820-4b24-ae7e-998436b6a138 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dd9b9794-6820-4b24-ae7e-998436b6a138');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-38e19096-60d6-4f98-be55-e831faac524b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-38e19096-60d6-4f98-be55-e831faac524b')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-38e19096-60d6-4f98-be55-e831faac524b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataframe = df.iloc[:8000]\n",
        "val_dataframe = df.iloc[8000:]"
      ],
      "metadata": {
        "id": "y-sWS7YONiFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dataframe_to_dataset(dataframe):\n",
        "    dataframe = dataframe.copy()\n",
        "    labels = dataframe.pop(\"Exited\")\n",
        "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
        "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
        "    return ds\n",
        "\n",
        "\n",
        "train_ds = dataframe_to_dataset(train_dataframe)\n",
        "val_ds = dataframe_to_dataset(val_dataframe)"
      ],
      "metadata": {
        "id": "pnjqnymDMsVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = train_ds.batch(32)\n",
        "val_ds = val_ds.batch(32)"
      ],
      "metadata": {
        "id": "5HRfq8mOOLf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(13,), dtype=\"float32\")\n",
        "x = keras.layers.Dense(32, activation=\"relu\")(inputs)\n",
        "#x = keras.layers.Dropout(0.05)(x)\n",
        "#x = keras.layers.LayerNormalization(x)\n",
        "output = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, output)\n",
        "model.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "XBvG8Ay5OwTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_ds, epochs=50, validation_data=val_ds)\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred = (y_pred > 0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 685
        },
        "id": "09v0JLCgOVO6",
        "outputId": "3aa10b8b-5669-4572-97de-3a8e030ea683"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-76-042d3d3ad950>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1080, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\", line 197, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Missing data for input \"input_17\". You passed a data dictionary with keys ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary', 'Geography_France', 'Geography_Germany', 'Geography_Spain', 'Gender']. Expected the following keys: ['input_17']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Input functionality already batches so try batch norm"
      ],
      "metadata": {
        "id": "bQjvTAzEOahB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BChyQd-jS5j5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mAk4GOF3OajI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}